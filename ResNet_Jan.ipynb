{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, \\\n",
    "    Add, AveragePooling2D, Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_bn(inputs: Tensor) -> Tensor:\n",
    "    relu = ReLU()(inputs)\n",
    "    bn = BatchNormalization()(relu)\n",
    "    return bn\n",
    "\n",
    "\n",
    "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = (3,3)) -> Tensor:\n",
    "    y = Conv2D(kernel_size=kernel_size,kernel_initializer='he_uniform',kernel_regularizer=l2(0.0001),\n",
    "               strides=(1 if not downsample else 2),\n",
    "               filters=filters,\n",
    "               padding=\"same\")(x)\n",
    "    y = relu_bn(y)\n",
    "    y = Conv2D(kernel_size=kernel_size,kernel_initializer='he_uniform',kernel_regularizer=l2(0.0001),\n",
    "               strides=1,\n",
    "               filters=filters,\n",
    "               padding=\"same\")(y)\n",
    "    if downsample:\n",
    "        x = Conv2D(kernel_size=1,\n",
    "                   strides=2,\n",
    "                   filters=filters,\n",
    "                   padding=\"same\")(x)\n",
    "\n",
    "    out = Add()([x, y])\n",
    "    out = relu_bn(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "def ResNet():\n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "    num_filters = 32\n",
    "\n",
    "    t = Conv2D(kernel_size=(3,3),kernel_initializer='he_uniform',kernel_regularizer=l2(0.0001),\n",
    "               strides=1,\n",
    "               filters=num_filters,\n",
    "               padding=\"same\")(inputs)\n",
    "    t = BatchNormalization()(t)\n",
    "    t = relu_bn(t)\n",
    "\n",
    "    num_blocks_list = [3,9]\n",
    "    for i in range(len(num_blocks_list)):\n",
    "        num_blocks = num_blocks_list[i]\n",
    "        for j in range(num_blocks):\n",
    "            t = residual_block(t, downsample=(j == 0 and i != 0), filters=num_filters)\n",
    "        num_filters *= 2\n",
    "\n",
    "    t = GlobalAveragePooling2D()(t)\n",
    "    t = Flatten()(t)\n",
    "    outputs = Dense(10, activation='softmax')(t)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    lr = 0.1\n",
    "    optimizer = SGD(learning_rate=lr, momentum=0.9)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_diagnostics(history, epOchs):\n",
    "\tepochs = list(range(0,epOchs))\n",
    "\n",
    "\ttrain_loss = history.history['loss']\n",
    "\ttrain_acc = history.history['accuracy']\n",
    "\n",
    "\tval_loss = history.history['val_loss']\n",
    "\tval_acc = history.history['val_accuracy']\n",
    "\n",
    "\n",
    "\tfig, ax = plt.subplots(nrows=2, ncols=1, figsize=(8, 6))\n",
    "\tax[0].plot(epochs, train_loss, color='green', label=\"Training loss\")\n",
    "\tax[0].plot(epochs, val_loss, color='red', label=\"Validation loss\")\n",
    "\n",
    "\tax[0].legend()\n",
    "\tax[0].set(ylabel='Cross Entropy Loss')\n",
    "\tax[0].grid()\n",
    "\n",
    "\tax[1].plot(epochs, train_acc, color='green', label=\"Training accuracy\")\n",
    "\tax[1].plot(epochs, val_acc, color='red', label=\"Validation accuracy\")\n",
    "\n",
    "\tax[1].legend()\n",
    "\tax[1].set(xlabel='Epochs', ylabel='Classification Accuracy (%)')\n",
    "\tax[1].grid()\n",
    "\n",
    "\t# save plot to file\n",
    "\troot_path = os.path.abspath(os.getcwd())\n",
    "\tplt.savefig(os.path.join(root_path,'Plots_jan' f'ResNet_Jan.png'))\n",
    "\tplt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(reduce_data=False):\n",
    "    (trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "\n",
    "    train_norm = trainX.astype('float32')\n",
    "    test_norm = testX.astype('float32')\n",
    "\n",
    "    mean_train = np.mean(trainX,axis=(1,2,3),keepdims=True)\n",
    "    std_train = np.std(trainX, axis=(1,2,3),keepdims=True)\n",
    "\n",
    "    mean_test = np.mean(testX,axis=(1,2,3),keepdims=True)\n",
    "    std_test = np.std(testX, axis=(1, 2, 3), keepdims=True)\n",
    "\n",
    "    trainX = (train_norm - mean_train) / std_train\n",
    "    testX = (test_norm - mean_test) / std_test\n",
    "\n",
    "    trainY = to_categorical(trainY)\n",
    "    testY = to_categorical(testY)\n",
    "    if reduce_data==True:\n",
    "        return trainX[:10000],trainY[:10000],testX,testY\n",
    "    else:\n",
    "        return trainX,trainY,testX,testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_label(y, pattern, ratio, one_hot=True):\n",
    "    #y: true label, one hot\n",
    "    #pattern: 'pair' or 'sym'\n",
    "    #p: float, noisy ratio\n",
    "    \n",
    "    #convert one hot label to int\n",
    "    if one_hot:\n",
    "        y = np.argmax(y,axis=1)#[np.where(r==1)[0][0] for r in y]\n",
    "    n_class = max(y)+1\n",
    "    \n",
    "    #filp label\n",
    "    for i in range(len(y)):\n",
    "        if pattern=='sym':\n",
    "            p1 = ratio/(n_class-1)*np.ones(n_class)\n",
    "            p1[y[i]] = 1-ratio\n",
    "            y[i] = np.random.choice(n_class,p=p1)\n",
    "        elif pattern=='asym':\n",
    "            y[i] = np.random.choice([y[i],(y[i]+1)%n_class],p=[1-ratio,ratio])            \n",
    "            \n",
    "    #convert back to one hot\n",
    "    if one_hot:\n",
    "        y = np.eye(n_class)[y]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "class CustomImageDataGenerator(ImageDataGenerator):\n",
    "    def __init__(self, cutout_mask_size = 0, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.cutout_mask_size = cutout_mask_size\n",
    "        \n",
    "    def cutout(self, x, y):\n",
    "        return np.array(list(map(self._cutout, x))), y\n",
    "    \n",
    "    def _cutout(self, image_origin):\n",
    "        image = np.copy(image_origin)\n",
    "        mask_value = image.mean()\n",
    "\n",
    "        h, w, _ = image.shape\n",
    "        top = np.random.randint(0 - self.cutout_mask_size // 2, h - self.cutout_mask_size)\n",
    "        left = np.random.randint(0 - self.cutout_mask_size // 2, w - self.cutout_mask_size)\n",
    "        bottom = top + self.cutout_mask_size\n",
    "        right = left + self.cutout_mask_size\n",
    "\n",
    "        if top < 0:\n",
    "            top = 0\n",
    "        if left < 0:\n",
    "            left = 0\n",
    "\n",
    "        image[top:bottom, left:right, :].fill(mask_value)\n",
    "        return image\n",
    "    \n",
    "    def flow(self, *args, **kwargs):\n",
    "        batches = super().flow(*args, **kwargs)\n",
    "\n",
    "        while True:\n",
    "            batch_x, batch_y = next(batches)\n",
    "            \n",
    "            if self.cutout_mask_size > 0:\n",
    "                result = self.cutout(batch_x, batch_y)\n",
    "                batch_x, batch_y = result                        \n",
    "                \n",
    "            yield (batch_x, batch_y)     \n",
    "\n",
    "datagen_parameters = {\"horizontal_flip\": True, \"width_shift_range\": 0.1, \"height_shift_range\": 0.1, \"cutout_mask_size\": 16}\n",
    "datagen = CustomImageDataGenerator(**datagen_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import time\n",
    "\n",
    "lr = 0.1\n",
    "\n",
    "class LearningController(Callback):\n",
    "    def __init__(self, num_epoch=0, learn_minute=0):\n",
    "        self.num_epoch = num_epoch\n",
    "        self.learn_second = learn_minute * 60\n",
    "        if self.learn_second > 0:\n",
    "            print(\"Leraning rate is controled by time.\")\n",
    "        elif self.num_epoch > 0:\n",
    "            print(\"Leraning rate is controled by epoch.\")\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        if self.learn_second > 0:\n",
    "            self.start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.learn_second > 0:\n",
    "            current_time = time.time()\n",
    "            if current_time - self.start_time > self.learn_second:\n",
    "                self.model.stop_training = True\n",
    "                print(\"Time is up.\")\n",
    "                return\n",
    "\n",
    "            if current_time - self.start_time > self.learn_second / 2:\n",
    "                self.model.optimizer.lr = lr * 0.1            \n",
    "            if current_time - self.start_time > self.learn_second * 3 / 4:\n",
    "                self.model.optimizer.lr = lr * 0.01\n",
    "                \n",
    "        elif self.num_epoch > 0:\n",
    "            if epoch > self.num_epoch / 2:\n",
    "                self.model.optimizer.lr = lr * 0.1            \n",
    "            if epoch > self.num_epoch * 3 / 4:\n",
    "                self.model.optimizer.lr = lr * 0.01\n",
    "                    \n",
    "        print('lr:%.2e' % self.model.optimizer.lr.value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY, testX, testY = load_and_prepare_data()\n",
    "trainY = flip_label(trainY, \"sym\", 0.05, True)\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "path = os\n",
    "checkpoint = ModelCheckpoint(filepath = \"ResNet-for-CIFAR-10.h5\", monitor=\"val_accuracy\", verbose=1, save_best_only=True)\n",
    "learning_controller = LearningController(epochs)\n",
    "callbacks = [checkpoint, learning_controller]\n",
    "model = ResNet()\n",
    "#print(model.summary())\n",
    "\n",
    "#datagen = ImageDataGenerator(width_shift_range=0.1,height_shift_range=0.1,horizontal_flip=True)\n",
    "it_train =datagen.flow(trainX,trainY,batch_size=batch_size)\n",
    "steps = int(trainX.shape[0]/batch_size)\n",
    "history = model.fit(it_train,steps_per_epoch=steps,epochs=epochs,validation_data=(testX,testY),callbacks=callbacks, verbose=1)\n",
    "summarize_diagnostics(history,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6563df1e0326027644e1fb251e3f7c2b0f92920a4e6c3d0059086ac7c4851cbb"
  },
  "kernelspec": {
   "display_name": "dl_project",
   "language": "python",
   "name": "dl_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
